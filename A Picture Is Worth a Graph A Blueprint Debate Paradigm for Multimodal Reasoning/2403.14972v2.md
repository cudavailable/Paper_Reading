## 标题：
A Picture Is Worth a Graph: A Blueprint Debate Paradigm for Multimodal Reasoning
一幅图片值得一个图表：一个多模态推理的蓝图辩论范式

## 关键词：
multi-modal reasoning; multi-agent debate; large language models

## 术语：

### Multi-modal reasoning：
	基于多种不同类型的数据（如文本、图像、视频等）进行推理和决策的能力。这种推理需要结合不同模态的信息来解决问题，通常涉及不同感知方式的数据。例如，结合图像和文本信息来回答关于图像内容的问题，或者结合音频和文本信息来进行语音识别和理解。这种方法可以使计算机系统更接近人类的感知和决策方式，从而提高系统在复杂环境中的适应能力和效果。

### multi-agent debate：
	通过模拟不同智能体之间的辩论和对话，以促进自我学习和逻辑思考。这种技术通常涉及在一个虚拟环境中设定多个智能体，它们可以就给定话题或问题展开辩论和讨论。
	在多智能体辩论中，每个智能体代表不同的观点或利益，它们通过对话和辩论来表达和捍卫自己的立场。这种对话过程可以激发思维，促使智能体更深入地思考问题，从而提高其逻辑推理和决策能力。

### Chain-of-Thoughts：
	一种认知心理学概念，用于描述人类思维中一系列相关联的想法或思考过程。这个概念强调人类思维的连贯性和逻辑性，认为人们的思维过程通常是基于一连串相互关联的概念或想法。

### Blueprint Debate：
	一种讨论或辩论形式，其中参与者根据一份详细的计划或蓝图进行讨论。在这种讨论中，与会者可能会就该蓝图的各个方面展开讨论，包括其目标、实施方法、可行性等进行深入探讨。

## 内容：

### 1 INTRODUCTION:

**multi-modal reasoning**：
1. 从不同的模式中创建一个统一的语义表示。
2. 整合这些不同的语义，同时确保逻辑上的一致性。

**挑战**：即使在单NLP任务中，整合不同的语义仍然有困难。

**multi-agent debate -- 可能的解决方法**
	多个LLM分别扮演不同的角色，从自己的角度陈述既定话题，最后达成共识。故为了融合多个模态进行推理，可以让每个LLM代表一个模态。

**可能遇到的问题**：
1. 为使不同agent之间的意见达成一致，而使陈述过于宽泛。
2. 注意力转移，分心，从一个概念讲到另外一个有关联的概念。

由于原来的NLP任务中概念和CoT是有限的，故**自下而上归纳**的debate方法适用。但多模态领域的信息远远更丰富，上述问题出现概率将增大。

*基于蓝图辩论可以限定讨论范围，聚焦陈述点的想法，提出BDoG。*

**Blueprint Debate on Graph：正式解决方案**
1. 先从模态中整合概念，并将它们之间的关系融合到一个初始图中作为蓝图。
2. 辩论自顶向下，并标记图中的结论，以保留具体的概念。
3. 新引入的概念被纳入相关分支，而不是作为上下文中的词级思想。这减少了焦点转移的可能性，因为在BDoG中，语义上的竞争发生在分支级别，而不是单词级别。

### 2 RELATED WORKS

- 2.1 Multimodal Reasoning
- 2.2 Multi-agent Debate
- 2.3 Graph-augmented LLMs

### 3 PRELIMINARY

### 4 BLUEPRINT DEBATE ON GRAPH：

**第i轮的BDoG用四元组表示**：
T𝑖 = (G𝑖 , S, A, F )
- G：思维图
- S：多模态源，S = {Q, I, C}
- A：动作集，A = {ai}
- F：agent执行的操作集，F = {fk}
- 每一轮结束时，G𝑖会被更新成G𝑖+1

#### 4.1 Blueprint G 0 Initialization：

- Conversion : **S -> G0** by operation **f0**
- f0包含了若干对子操作，对文本的和对图像的。

**限制**：Size Constraint & Relevance Constraint

e.g.
**𝑆𝑖𝑧𝑒** : The graph must not be empty. Please restrict the maximum number of objects in the graph to 20.
**𝑅𝑒𝑙𝑒𝑣𝑎𝑛𝑐𝑒** : The objects and relations within the graph should be pertinent to addressing the question.

#### 4.2 Agents and Roles：

三种角色 R = {𝑃𝑟𝑜𝑝𝑜𝑛𝑒𝑛𝑡,𝑂𝑝𝑝𝑜𝑛𝑒𝑛𝑡, 𝑀𝑜𝑑𝑒𝑟𝑎𝑡𝑜𝑟 }

**Proponent**：
- 给定身份提示，做出正面推理，将Gi修改成正面证据G+。
- 给定证据Gi，问题f(Q)和图像f(I)，限制Size/ Revelance / Compactness。

**Opponent**：
- 给定身份提示，做出反驳，将正面证据G+改成G-。
- 给定正面证据G+，问题f(Q)和图像f(I)，限制Size/ Revelance / Compactness。

**Moderator**：
- 给定身份提示，做出综合总结，将正面证据G+和反面证据G-整合成G*。
- 给定正面证据G+和反面证据G-，解决问题f(Q)和图像f(I)，限制Size/ Revelance / Compactness。

#### 4.3 Debate Progress and Graph Condensation：

1. Initialization and Role Assignment：
	分成三派，正方、反方和中立。正反双方角色数相同，中立角色唯一。
2. Debating：
	正反方轮流发表，中立总结。若没有总结则G-作为Gi+1，反之则作为最终结果并采用。
3. Stopping Criteria：
	当Gi+1和Gi距离很小时停止。

### 5 EXPERIMENTS:

#### 5.1 Backbone Models：
1) GeminiProVision
2) InstructBLIP and LLaVA-v1.5
3) GPT-4

#### 5.2 Datasets and Metrics：
1) ScienceQA-IMG
2) MMbench

#### 5.3 Performance Comparison to SOTA Methods：

**两类SOTA方法**：
1. 开源
2. 闭源

**BDoG优于SOTA方法**：
1. BDoG helps reduce the performance gap between large and small models.
2. BDoG reinforces the multimodal reasoning.

#### 5.4 Ablation Study：

**Decomposition**:
- BDoG𝐷𝑒𝑏𝑎𝑡𝑒 : we remove the graph regulation and constraints, resulting in a debate-only approach.
- BDoG𝐺𝑟𝑎𝑝ℎ: we remove the debating rounds, resulting in a graph-based reasoning method.

**Conlusion**：
BDoG leverages the advantages of both structured evidence through graph regulation and iterative refinement through debating.

#### 5.5 Monitoring The Debating Progress：

- 模型通常在2-3轮时收敛。
- 随着辩论轮数增加，不一致和错误在减少。

#### 5.6 Efficiency Analysis：

Effectiveness & Efficiency : BDoG > BDoG𝐷𝑒𝑏𝑎𝑡𝑒

### 6 CONCLUSION

很好地解决了前述问题，达成新的SOTA。