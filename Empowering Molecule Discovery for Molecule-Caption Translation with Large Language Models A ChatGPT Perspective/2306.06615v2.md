#### 标题：
Empowering Molecule Discovery for Molecule-Caption Translation with Large Language Models: A ChatGPT Perspective
利用大型语言模型为分子说明翻译提供分子发现能力：ChatGPT 视角

#### 关键词：
Drug Discovery, Large Language Models (LLMs), In-context Learning, Retrieval Augmented Generation.

#### 术语：
##### molecule-caption translation ：分子说明翻译
	将分子结构图像或描述性信息翻译为自然语言文本的过程。旨在促进分子结构信息的自动化处理和理解，为化学和生物领域的研究提供更加便捷和高效的工具和方法。

##### In-context Learning ：上下文学习
	一种学习方式，强调学习过程应与特定的实际应用情境相结合，以提高学习效果和应用能力。

##### Retrieval Augmented Generation：检索增强生成
	一种结合了信息检索和自然语言生成的方法。通过结合检索模型和生成模型，可以利用检索到的外部知识、语境或信息来指导生成模型，以生成更具信息丰富性和准确性的文本。

##### simplified molecular-input line-entry system (SMILES)
	是一种用来表示化学结构的文本字符串表示法，通常用于计算机化学中。SMILES字符串由一系列字符组成，描述了化合物的结构信息，包括原子、键和拓扑关系等。

##### Molecule-Caption Retrieval
	从包含分子结构信息的数据集中检索与特定分子相关联的文本描述或说明

##### KV-PLM：
	Knowledge-Augmented Pre-trained Language Model，这种模型结合了自然语言处理领域中的预训练语言模型技术和知识图谱等外部知识源，以增强模型在语言理解和生成任务中的表现。

##### MOLREGPT：
	Molecule-Recognition Pre-trained Model，这种模型是为了处理分子结构数据而设计的预训练模型，旨在帮助理解和分析化学领域中的分子结构信息。

##### Prompt Management：
	指在使用自然语言处理模型（如生成式预训练模型）时，通过设计和优化输入提示（prompt）来引导模型生成所需的输出。这个过程通常涉及创建具有特定格式和内容的文本片段，以启发模型产生相关的回应或输出。

##### Generation Calibration：
	"生成校准"指的是调整或微调生成模型的输出，使其更准确、可靠或符合特定标准或约束条件的过程。这一校准步骤对于确保生成的内容符合一定标准，如语言连贯性、事实准确性或风格一致性至关重要。

##### Morgan Fingerprints：
	摩根指纹是一种分子指纹算法，用于描述和表示分子结构。是一种基于环的分子指纹，它将分子结构映射到一个固定长度的二进制字符串中。这种指纹算法通过遍历分子的环来编码分子的拓扑结构信息，以便于分子之间的相似性比较和计算。可用于计算分子之间的相似性，从而在化学信息检索和药物设计等领域中发挥重要作用。

##### IUPAC names：
	是一种根据IUPAC制定的一套规则对化合物进行命名的系统化方式。这些名称用于提供一个标准化且明确的方式来指代化学物质。

##### functional group positions:
	指的是有机分子中特定官能团（functional group）相对于分子结构中其他部分的位置。在有机化学中，官能团是分子中具有特定化学性质和反应活性的基团。确定官能团位置对于理解分子的性质、化学反应以及分子之间的相互作用至关重要。它可以影响分子的化学性质、反应性以及在生物体系中的功能。

##### BM25（Best Matching 25）:
	是一种用于信息检索的概率模型，通常用于评估文档与查询之间的相关性。它是一种改进的基于概率的信息检索算法，旨在解决传统的TF-IDF算法在长文档和短查询时的效率和准确性问题。

#### 内容：

##### 1 Introduction：

**立意**：理解分子、了解其功能可促进化学、药学、材料科学等领域的发展。

**分子表示**：SMILES    Morgan Fingerprints

**两个子任务**：molecule captioning (Mol2Cap) & text-based molecule generation (Cap2Mol)

**限制：**
	1. 模型架构的设计高度依赖领域专家的介入，限制了AI促进分子发现的进程。
	2. 大多数方法遵循预训练微调模式，对计算和领域资源有要求。
	3. Text2Mol & MolT5这些已有的方法不能生成未见的例子。

**解决方向：** LLM的新进展达成了许多成就。不必微调，通过上下文学习LLM即可展现其优秀的泛化和推理能力，处理未见问题。

**新的挑战**：
	1. LLM(GPT3.5/4.0)的架构和参数未公开，不能在下游任务上微调。
	2. LLM对计算资源、领域语料库以及能源有着高要求。
	3. 仍缺乏合适的模型来帮助科学研究者进行研发。

**贡献：**
	1. In Context Few-Shot Molecule Learning
	2. MolReGPT
	3. Comprehensive experiments on a real-world dataset

##### 2 Related Work:
*Molecule Discovery*
*LLM*
*MOLREGPT*
	*Molecule-Caption Retrieval,*
	*Prompt Management,* 
	*In-Context Few-Shot Molecule Learning,*
	*and Generation Calibration,* 
	*following the workflow of preprocessing, querying, and post-processing.*

##### 3 MOLREGPT：

###### 3.1  Molecule-Caption Retrieval:

*利用Molecule-Caption Retrieval -> 有着相似分子说明(功能性质)的分子可以被找到 -> LLM洞察自然语言和分子之间的联系*

*Morgan Fingerprints解决SMILES表示不能很好展现分子二维结构特性的问题* 
*-> 用Dice相似度来进行分子检索*

*BM25 -> caption检索*

###### 3.2  Prompt Management:

*System prompts and user input prompts are two important parts to enable the in-context learning ability of LLMs.*

- *Role Identification -> 鼓励LLM生成和专业知识一致的响应*
- *Task Description -> 确保LLM对要解决的问题概念有清楚的理解*
- *Context Examples -> 允许LLM通过上下文学习来利用mol-caption pair中包含的信息来产生更好的响应*
- *Output Instruction -> 明确响应格式*

###### 3.3 In-Context Few-Shot Molecule Learning:

*Recently, as an alternative to fine-tuning, in-context learning provides great opportunities to teach LLMs to make predictions based on a few context examples.*

*system prompt -> 为 molecule-caption translation 建立专业知识*
*user prompt -> 将模型的注意力聚焦到特定的用户输入上*

*解释了Fine-tuning/Prompting/In-Context Few-Shot Molecule Learning的区别*

###### 3.4 Generation Calibration：

*解决不合理的输出格式和拒绝回答等响应问题*

##### 4 EXPERIMENT：

###### 4.1 Experimental Settings：

- ***Dataset** : public dataset ChEBI-20 containing 33,010 molecule-caption pairs*
- ***Evaluation Metrics** : 采用与MolT5相同的评估方式*
- ***Baselines**：Transformer(没有预训练) / T5(预训练但不是在领域数据集) / MolT5(语言文本和SMILES字符串上预训练，再在ChEBI-20微调)*

###### 4.2 Performance Comparison

- *粗略地，MolReGPT > MolT5-large > Transformer*

###### 4.3 Ablation Study：

- *Impact of Retrieval Strategies : Morgan FTS > BM25 > random*
- *Impact of Example Number for In-Context Learning：随着样本个数n的增大，模型上下文学习的情况就越好，但是对于样本长度是有输入限制的(实验中取了1,2,5,10)*

##### 5 CONCLUSION：

- BM25 caption retrieval
- Morgan Fingerprints and Dice similarity are adopted to retrieve similar molecules
- MolReGPT, a general retrieval based in-context learning paradigm that empowers molecule discovery with LLMs like ChatGPT via In-Context Few-Shot Molecule Learning

##### 6 BROADER IMPLICATION & FUTURE DIRECTIONS：

- 用更强的LLM
- 用更好地检索算法
- 举一反三，开拓更多应用领域，思考AI还能怎样将分子空间和文本空间联系起来